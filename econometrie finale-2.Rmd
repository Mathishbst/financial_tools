
title: "Études des cycles financier"
author: "Fabien Noisette, Mathis Herbst, Maja Hemms et Maïwenn Patron"
date: "Mardi 11 Février 2025"
output:
  pdf_document:
    toc: true
  html_document:
    toc: true
    toc_float: true
    number_section: false
    theme: flatly
    df_print: paged
lang: fr
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(readxl)
library(readr)
library(dplyr)
library(tidyverse)
library(caret)
library(ROCR)
library(plm)
```

# Point de vue sur les données

## Importation des données

```{r data}
data <- read_excel("econometriefinale.xlsx", sheet=1)
```


## Vérification des données

```{r traitement1}
head(data)
nrow(data)
ncol(data)
sum(is.na(data))
```

Il y a un total de **2718** observations, pour un total de **56** variables différentes, plus que suffisante pour l'analyse.
On remarque qu'il existe une grande quantité de données "NA" (**31457**). On va ainsi se concentrer sur les variables contenant le moins de ces données manquantes.

## Première analyse des données

Une façon éclairée de choisir une bonne direction pour notre analyse est de vérifier la matrice de corrélation entre une donnée préexistante "*crisis*", variable indicatrice indiquant si l'année correspond à une crise et les autres variables du jeu de données

On remarque par exemple que pour les États-Unis, *crisis* nous donne 1 pour les années 2008, 1930, qui correspond à des crises connues pour ce pays.

Ainsi cela va nous permettre d'obtenir les variables les plus sensibles à ces périodes

```{r}
variables_a_tester <- c("gdp", "rgdpbarro", "money", "cpi", "ca", "stir", "ltrate", "debtgdp", "tloans", "ltd", "lev", "noncore", "eq_capgain", "eq_div_rtn", "bond_rate", "hpnom", "housing_capgain", "tmort", "unemp", "peg")
cor_matrix <- cor(na.omit(data[, c("crisis", variables_a_tester)]), use = "complete.obs", method = "pearson")
cor_matrix["crisis", ]
```

On remarque que des variables comme *stir* ou *ltd* ont un grande corrélation positive avec *crisis*, et que *eq_capgain* et *ca* ont également une grande corrélation positive avec *crisis*. Ainsi nous pourrons partir sur ces variables.

## Description des variables utilisées :
* *stir* : Short-term Interest Rate, Taux d'intérêt à court terme, exprimé en pourcentage annuel.
* *ltd* : Loan-to-Deposit Ratio, Ratio prêt/dépôt des banques.
* *eq_capgain* : Equity Capital Gain, Gain en capital sur les actions.
* *ca* : Current Account Balance, Balance courante du pays.
* *gdp* : Growt Domestic Prduct, PIB du pays.

```{r traitement2}
datatrait <- data.frame(year = data$year, country = data$country, crisis = data$crisis, ltd = data$ltd, stir = data$stir, eq_capgain = data$eq_capgain, ca = data$ca, gdp = data$gdp)
summary(datatrait)
```

On remarque également que ces variables contiennent 'relativement' peu de données manquantes, qui est un plus pour notre analyse.

# Premier travail sur les régressions :

Nous utiliserons ici por les régressions des modèles de type ***Logit***, nous permettant de prédire une variable qualitative (ou indicatrice) à l'aide de variable quantitative.

## Régressions individuelles

On va tout d'abord régresser crisis par rapport à chaque variable.

### Avec *ltd*

```{r}
dftemp <- data[!is.na(data$crisis) & !is.na(data$ltd), ]
logit_model1 <- glm(crisis ~ ltd, dftemp, family = binomial)
summary(logit_model1)
```

On remarque que *ltd* est très significative lorsque *crisis* est regréssée toute seule avec celui-ci. Nous pouvons faire un graph représentant la relation entre ce ratio et la probabilité de crise.

```{r}
dftemp$predicted_prob <- predict(logit_model1, type = "response")

ggplot(dftemp, aes(x = ltd, y = predicted_prob)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), color = "blue") +
  labs(title = "Probabilité de crise en fonction du ratio LTD",
       x = "Loan-to-Deposit Ratio (LTD)",
       y = "Probabilité estimée de crise")
```

### Avec *eq_capgain*

```{r}
dftemp <- data[!is.na(data$crisis) & !is.na(data$eq_capgain), ]
logit_model2 <- glm(crisis ~ eq_capgain, dftemp, family = binomial)
summary(logit_model2)
```

On remarque que *eq_capgain* n'est pas du tout significatif lorsque *crisis* est regréssée toute seule avec celui-ci. Nous pouvons faire un graph représentant la relation entre ce ratio et la probabilité de crise.

```{r}
dftemp$predicted_prob <- predict(logit_model2, type = "response")

ggplot(dftemp, aes(x = ltd, y = predicted_prob)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), color = "blue") +
  labs(title = "Probabilité de crise en fonction de eq_capgain",
       x = "Equity Capital Gain",
       y = "Probabilité estimée de crise")
```

On remarque que la variable *eq_capgain* n'a pas  de pouvoir explicatif dans ce modèle, peut être parce que la spécification ne montre pas bien le pouvoir explicatif de la variable.

Nous allons donc régresser *crisis* avec toutes les variables :

```{r}
dftemp <- data[!is.na(data$crisis) & !is.na(data$eq_capgain), ]
logit_model2 <- glm(crisis ~ eq_capgain + ltd + stir + gdp + ca, dftemp, family = binomial)
summary(logit_model2)

```

on remarque tout de suite que *eq_capgain* capte le plus de pouvoir explicatif, avec un p-value extrèmement faible (**< 2e-16**)

# Analyse des faux positifs avec une matrice de confusion :

```{r}
modele_logit <- glm(crisis ~ stir + ltd + eq_capgain + ca, 
                    data = datatrait, 
                    family = binomial)

datatrait$prob_crisis <- predict(modele_logit, newdata = datatrait, type = "response")

summary(datatrait$prob_crisis)

datatrait$pred_crisis <- ifelse(datatrait$prob_crisis > 0.5, 1, 0)

confusionMatrix(as.factor(datatrait$pred_crisis), as.factor(datatrait$crisis))

```

## Explication Matrice de confusion: 

On voit qu’ici il y a 1766 vrai négatifs cela signifie le nombre de fois ou le modèle a prédit correctement “pas de crise”. 
On voit qu’il y a 58 faux négatifs ce qui signifie que 58 crises qui ont eu lieu n’ont pas été détectées. 
On voit qu’il y a 4 faux positifs cela signifie qu’à 4 reprises le modèle a prédit une crise alors qu'il n'y en avait pas.
On voit qu’il y a 6 vrais positifs cela veut dire que 6 crises ont été correctement prédites. 

On remarque aussi en regardant “Accuracy : 0.9662  “ que le modèle est correct 96,62% du temps. 

# Analyse des résultats avec AUROC :

L'objectif est de tracer des courbes ROC pour correctement visualiser le taux de faux positif et de vrai positif, afin de montrer le pouvoir de significatvité d'une variable.

## Code R



```{r}
df_model <- datatrait %>%
  select(crisis, stir, gdp, ltd, eq_capgain, ca) %>%
  drop_na() 
# Liste des variables à tester individuellement
variables <- c("stir", "gdp", "ltd", "eq_capgain", "ca")
colors <- c("blue", "green", "purple", "orange", "brown") 

# Initialiser le graphique
plot(NULL, xlim = c(0,1), ylim = c(0,1), 
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "Comparaison des courbes ROC - Modèle Logit")

# Ajouter une ligne diagonale pour référence (modèle aléatoire)
abline(0,1, col = "black", lty = 2)

# Boucle pour tester plusieurs modèles probit
auc_values <- c()  # Stocker les AUC

for (i in seq_along(variables)) {
  var <- variables[i]
  color <- colors[i]
  
  # Construire le modèle Probit avec UNE SEULE variable
  logit_model <- glm(as.formula(paste("crisis ~", var)), data = datatrait, family = "binomial")
  
  # Prédictions sur les mêmes données
  df_model$pred_prob <- predict(logit_model, newdata = df_model, type = "response")
  
  # Générer les données ROC
  pred <- prediction(df_model$pred_prob, df_model$crisis)
  perf <- performance(pred, "tpr", "fpr")
  
  # Tracer la courbe ROC pour cette variable
  lines(perf@x.values[[1]], perf@y.values[[1]], col = color, lwd = 2)
  
  # Ajouter une légende pour identifier chaque variable
legend("bottomright", legend = variables, col = colors, lty = 1, lwd = 2)
  
  # Calcul de l'AUC
  auc <- performance(pred, "auc")@y.values[[1]]
  auc_values <- c(auc_values, auc)
  print(paste("AUC pour", var, "(Probit):", auc))
}


```


## Interprétation des résultats : 

La courbe en orange est *eq_capgain*. Il s'agit de la variable donnant le moins de faux positifs
La courbe en violet est celle qui est 2ème, c’est le ltd.

L'AUC (Area Under the Curve) mesure la capacité prédictive d'un modèle. Pour info, un AUC = 1 -> prédit parfaitement les crises. Ici avec le *eq_capgain* =79,8%, signifie que le equity capgain prédit à 79,8% les crises et le modèle 

Les valeurs des AUC : 

* "AUC pour *stir* : 0.606568504594821"
* "AUC pour *gdp* : 0.385129490392648"
* "AUC pour *ltd* : 0.67376775271512"
* "AUC pour *eq_capgain* : 0.798036758563074"
* "AUC pour *ca* : 0.557017543859651"

# Conclusion de cette première analyse :

On remarque que eq_capgain est la variable prédisant le mieux les crises financières.

Mais une meilleure façon d'analyser la prédictibilité de crisis en fonction de ces variables est d'introduire un lag dans les données.

Une autre bonne façon d'analyser est d'analyser avec des effets fixes pays afin d'isoler les crises particulières à un pays donné.

# Nouvelle approche 

Nous allons introduire des effets fixes par pays afin de prendre en compte les spécificités structurelles propres à chaque pays qui pourraient influencer la probabilité d’une crise. En effet, chaque pays possède des caractéristiques économiques, institutionnelles et politiques uniques qui ne varient pas nécessairement dans le temps, mais qui peuvent avoir un impact significatif sur la survenue des crises financières. En intégrant ces effets fixes, nous contrôlons les facteurs inobservables constants dans le temps, ce qui nous permet d'isoler l'impact des variables explicatives sur les crises. Cette approche évite les biais d’omission et améliore la robustesse des résultats en garantissant que les différences entre pays ne faussent pas l’estimation des coefficients. Ainsi, les variations des variables explicatives sont interprétées uniquement par rapport aux variations intra-pays, ce qui renforce la validité des conclusions sur les déterminants des crises.

On va ainsi faire des modifications pour retenter la même analyse avec OLS et des lags.

## Ajout des effets fixes pays et du lag

```{r}
datatraitb <- data.frame(year = data$year, country = data$country, crisis = data$crisis, ltd = data$ltd, stir = data$stir, eq_capgain = data$eq_capgain, ca = data$ca, gdp = data$gdp)

# Fonction pour ajouter un lag à une variable avec regroupement par pays
add_lag <- function(data, var_name, lag = 1) {
  data <- data %>%
    group_by(country) %>%  # Assurer que le lag est calculé par pays
    mutate(!!paste0(var_name, "_lag") := lag(get(var_name), lag)) %>%
    ungroup()
  return(data)
}


# Liste des variables économiques à lagger
variables <- c("stir", "gdp", "ltd", "eq_capgain", "ca")

# Appliquer le lag pour chaque variable
for (var in variables) {
  datatraitb <- add_lag(datatraitb, var, lag = 1)
}

# Sélectionner les nouvelles variables avec lag et la variable cible (crisis)
lagged_vars <- paste0(variables, "_lag")

df_model <- datatraitb %>%
  select(crisis, country, all_of(lagged_vars)) %>%
  drop_na()  # Supprimer les lignes avec des valeurs manquantes dues au lag

```

## Nouveaux graphiques

```{r, warning=FALSE}
# Initialiser le graphique
plot(NULL, xlim = c(0,1), ylim = c(0,1), 
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "Courbes ROC - OLS avec effets fixes et variables laggées")

# Ajouter une ligne diagonale pour référence (modèle aléatoire)
abline(0,1, col = "black", lty = 2)

# Boucle pour tester plusieurs modèles OLS avec les variables laggées et effets fixes
colors <- c("blue", "green", "purple", "orange", "brown", "red") 
auc_values <- c()  # Stocker les AUC

for (i in seq_along(lagged_vars)) {
  var <- lagged_vars[i]
  color <- colors[i]
  
  # Construire le modèle OLS avec effets fixes par pays
  ols_model <- plm(as.formula(paste("crisis ~", var)), 
                    data = df_model, 
                    model = "within",
                    index = c("country"))

  # Prédictions sur les mêmes données
  df_model$pred_prob <- predict(ols_model, newdata = df_model)

  # Générer les données ROC
  pred <- prediction(df_model$pred_prob, df_model$crisis)
perf <- performance(pred, "tpr", "fpr")

  # Tracer la courbe ROC pour cette variable
  lines(perf@x.values[[1]], perf@y.values[[1]], col = color, lwd = 2)

  # Calcul de l'AUC
  auc <- performance(pred, "auc")@y.values[[1]]
  auc_values <- c(auc_values, auc)
  print(paste("AUC pour", var, "(OLS avec effets fixes et lag t-1):", auc))
}

# Ajouter une légende pour identifier chaque variable
legend("bottomright", legend = lagged_vars, col = colors, lty = 1, lwd = 2)
```

Si une courbe ROC avec un lag est meilleure que la version sans lag, cela signifie que les variations passées influencent les crises.
Si l'AUC est plus élevée avec un lag, cela montre qu'une crise est mieux prédite par les valeurs passées de cette variable.
L’utilisation des effets fixes pays nous permet de corriger les biais liés aux différences entre pays (ex: politiques économiques différentes).

